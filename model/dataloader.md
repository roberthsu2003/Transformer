**torch.utils.data.DataLoader çš„åŠŸèƒ½èˆ‡ç°¡å–®ç¯„ä¾‹**

torch.utils.data.DataLoader æ˜¯ PyTorch ä¸­ç”¨ä¾†åŠ è¼‰æ•¸æ“šçš„å·¥å…·ï¼Œä¸»è¦ç”¨æ–¼æ‰¹é‡è™•ç†æ•¸æ“šã€éš¨æ©Ÿæ‰“äº‚æ•¸æ“šã€ä»¥åŠä¸¦è¡ŒåŠ è¼‰æ•¸æ“šï¼ˆåˆ©ç”¨å¤šç·šç¨‹åŠ é€Ÿï¼‰ã€‚é€šå¸¸èˆ‡ torch.utils.data.Dataset æ­é…ä½¿ç”¨ï¼Œä»¥ä¾¿æœ‰æ•ˆåœ°çµ„ç¹”æ•¸æ“šã€‚

**åŠŸèƒ½**


1. **æ‰¹é‡è™•ç† (Batching)**

â€¢ é€é batch_size è¨­å®šæ¯æ¬¡è®€å–çš„æ•¸æ“šé‡ï¼Œä½¿æ¨¡å‹èƒ½å¤ æ›´é«˜æ•ˆåœ°è™•ç†æ•¸æ“šã€‚


2. **éš¨æ©Ÿæ‰“äº‚ (Shuffling)**

â€¢ ä½¿ç”¨ shuffle=True ä¾†æ‰“äº‚æ•¸æ“šï¼Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚


3. **å¤šç·šç¨‹ä¸¦è¡ŒåŠ è¼‰ (Parallel Loading)**

â€¢ è¨­ç½® num_workers ä¾†å•Ÿç”¨å¤šç·šç¨‹åŠ è¼‰æ•¸æ“šï¼ŒåŠ å¿«æ•¸æ“šè®€å–é€Ÿåº¦ã€‚


4. **æ•¸æ“šå¢å¼· (Transformations)**

â€¢ å¯æ­é… torchvision.transformsï¼ˆå¦‚å½±åƒè™•ç†ï¼‰ä¾†é è™•ç†æ•¸æ“šã€‚


5. **è‡ªå®šç¾©æ•¸æ“šé›† (Custom Dataset)**

â€¢ å¯ä»¥ç¹¼æ‰¿ torch.utils.data.Dataset ä¾†å®šç¾©è‡ªå·±çš„æ•¸æ“šè®€å–æ–¹å¼ã€‚

**ç°¡å–®ç¯„ä¾‹**

1ï¸âƒ£ è®€å– Tensor æ•¸æ“š

```other
import torch
from torch.utils.data import DataLoader, TensorDataset

# å‰µå»ºç°¡å–®çš„ Tensor æ•¸æ“šé›†
x = torch.arange(10).float().unsqueeze(1)  # ç”Ÿæˆ 10 å€‹æ•¸æ“šé»
y = x * 2                                  # æ¨™ç±¤ç‚º x çš„ 2 å€
dataset = TensorDataset(x, y)              # å‰µå»ºæ•¸æ“šé›†

# ä½¿ç”¨ DataLoader è®€å–æ•¸æ“š
dataloader = DataLoader(dataset, batch_size=3, shuffle=True)

# è¿­ä»£æ•¸æ“š
for batch in dataloader:
    x_batch, y_batch = batch
    print(f"x_batch: {x_batch.squeeze().tolist()}, y_batch: {y_batch.squeeze().tolist()}")
```


ğŸ”¹ é‡é»

â€¢ ä½¿ç”¨ TensorDataset ä¾†å°è£ x, y æ•¸æ“šã€‚

â€¢ DataLoader è¨­å®š batch_size=3ï¼Œè®“æ¯æ¬¡è®€å– 3 ç­†æ•¸æ“šã€‚

â€¢ shuffle=True è®“æ•¸æ“šé †åºéš¨æ©ŸåŒ–ã€‚

2ï¸âƒ£ è®€å–è‡ªå®šç¾©æ•¸æ“šé›†

å¦‚æœæ•¸æ“šæ˜¯å¾ CSVã€åœ–ç‰‡æˆ–å…¶ä»–ä¾†æºç²å–ï¼Œé€šå¸¸éœ€è¦è‡ªå®šç¾© Datasetã€‚

```other
from torch.utils.data import Dataset

class CustomDataset(Dataset):
    def __init__(self):
        self.data = list(range(1, 11))  # å‡è¨­æœ‰ 10 ç­†æ•¸æ“š
    
    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        x = self.data[index]
        y = x * 2
        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)

# å‰µå»ºè‡ªå®šç¾©æ•¸æ“šé›†
dataset = CustomDataset()
dataloader = DataLoader(dataset, batch_size=3, shuffle=True)

# è¿­ä»£æ•¸æ“š
for x_batch, y_batch in dataloader:
    print(f"x_batch: {x_batch.tolist()}, y_batch: {y_batch.tolist()}")
```


ğŸ”¹ é‡é»

â€¢ **len** å®šç¾©æ•¸æ“šé›†çš„å¤§å°ã€‚

â€¢ **getitem** è¿”å›ä¸€å€‹æ•¸æ“šæ¨£æœ¬ (x, y)ã€‚

â€¢ DataLoader ä»ç„¶è² è²¬æ‰¹é‡åŠ è¼‰æ•¸æ“šã€‚

3ï¸âƒ£ è®€å–åœ–ç‰‡æ•¸æ“šï¼ˆä½¿ç”¨ torchvisionï¼‰

å°æ–¼åœ–ç‰‡æ•¸æ“šï¼Œå¯æ­é… torchvision.datasets å’Œ transforms ä½¿ç”¨ï¼š

```other
from torchvision import datasets, transforms

# å®šç¾©æ•¸æ“šè½‰æ›ï¼ˆæ¨™æº–åŒ–ã€è½‰ç‚º Tensorï¼‰
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

# ä¸‹è¼‰ä¸¦åŠ è¼‰ MNIST æ•¸æ“šé›†
dataset = datasets.MNIST(root="./data", train=True, transform=transform, download=True)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

# è®€å–ä¸€å€‹ batch çš„æ•¸æ“š
images, labels = next(iter(dataloader))
print(f"æ‰¹é‡åœ–ç‰‡å¼µæ•¸: {images.shape}, æ‰¹é‡æ¨™ç±¤: {labels.shape}")
```


ğŸ”¹ é‡é»

â€¢ transforms é€²è¡Œåœ–ç‰‡é è™•ç†ï¼ˆè½‰ Tensorã€æ¨™æº–åŒ–ï¼‰ã€‚

â€¢ ç›´æ¥ä½¿ç”¨ torchvision.datasets.MNIST ä¾†ä¸‹è¼‰æ•¸æ“šã€‚

â€¢ batch_size=64ï¼Œæ¯æ¬¡è®€å– 64 å¼µåœ–ç‰‡ã€‚

**ç¸½çµ**

â€¢ DataLoader æ˜¯ PyTorch æä¾›çš„é«˜æ•ˆæ•¸æ“šåŠ è¼‰å·¥å…·ï¼Œæ”¯æ´ **æ‰¹é‡è®€å–ã€éš¨æ©Ÿæ‰“äº‚ã€å¤šç·šç¨‹åŠ è¼‰**ã€‚

â€¢ å¯ä»¥é…åˆ TensorDataset æˆ– Dataset ä¾†è®€å–ä¸åŒé¡å‹çš„æ•¸æ“šï¼ˆå¦‚ Tensorã€åœ–ç‰‡ã€CSVï¼‰ã€‚

â€¢ å¯ä»¥ä½¿ç”¨ torchvision è™•ç†å½±åƒæ•¸æ“šï¼Œæ­é… transforms é€²è¡Œé è™•ç†ã€‚

é€™äº›åŠŸèƒ½è®“è¨“ç·´ç¥ç¶“ç¶²çµ¡æ›´åŠ æ–¹ä¾¿å’Œé«˜æ•ˆï¼ ğŸš€
