{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型下載與保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 連線下載\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8198fd5ab7dc43d48021a6c85bb3b5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/755 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f185c2a01dc4e9c8d48d890bf5aaa7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/755 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75542697f95549de85d051132bcab03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/185M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('hfl/rbt4', force_download=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用git clone下載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'rbt3'...\n",
      "remote: Enumerating objects: 48, done.\u001b[K\n",
      "remote: Total 48 (delta 0), reused 0 (delta 0), pack-reused 48 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (48/48), 156.45 KiB | 4.01 MiB/s, done.\n",
      "Filtering content: 100% (3/3), 442.86 MiB | 54.86 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/hfl/rbt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('rbt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"rbt3\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.46.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看模型參數\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"./rbt3\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 3,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.46.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#取出參數\n",
    "config = AutoConfig.from_pretrained('./rbt3')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型呼叫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2483, 2207, 4638, 2769,  738, 3300, 1920, 1918, 2682,  106,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = '弱小的我也有大夢想!'\n",
    "tokenizer = AutoTokenizer.from_pretrained('rbt3')\n",
    "inputs = tokenizer(sen, return_tensors='pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.4771,  0.3579,  0.5285,  ..., -0.6735,  0.6864,  0.1310],\n",
       "         [-0.5942, -0.2553,  0.4105,  ..., -0.0481, -0.4971, -0.5453],\n",
       "         [ 0.0680,  0.7082,  0.0255,  ..., -0.4590,  0.3631, -0.5337],\n",
       "         ...,\n",
       "         [ 0.4357,  0.2608, -0.1650,  ..., -0.1751,  0.2892, -0.1351],\n",
       "         [ 0.3449, -0.0044,  0.0611,  ..., -0.5794, -0.0655, -0.3862],\n",
       "         [ 0.4734,  0.3619,  0.5254,  ..., -0.6730,  0.6846,  0.1350]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.8378e-01, -8.4294e-01, -1.0000e+00, -8.6466e-01,  9.9086e-01,\n",
       "          1.3641e-01,  3.9330e-01,  5.3804e-02,  9.9394e-01,  9.9995e-01,\n",
       "          1.5517e-02, -1.0000e+00,  1.3823e-01,  9.9795e-01, -9.9999e-01,\n",
       "          9.9991e-01,  9.9394e-01,  9.7404e-01, -9.9421e-01, -4.2701e-02,\n",
       "         -9.3017e-01, -9.9267e-01,  1.1693e-01,  9.3277e-01,  9.9786e-01,\n",
       "         -9.9778e-01, -9.9999e-01,  1.4139e-01, -9.1800e-01, -9.9993e-01,\n",
       "         -9.9859e-01, -9.9983e-01,  2.9395e-01, -2.5487e-01,  9.9244e-01,\n",
       "         -9.8819e-01, -1.4355e-02, -9.9350e-01, -9.9973e-01, -9.9850e-01,\n",
       "         -8.0014e-02,  9.8284e-01,  9.1306e-02,  9.9991e-01,  5.6337e-02,\n",
       "          6.0610e-02,  9.9997e-01,  8.9020e-01, -9.6321e-02,  8.9666e-01,\n",
       "         -7.7871e-02, -2.1331e-01, -9.9057e-01,  9.9684e-01,  2.8458e-02,\n",
       "          1.2148e-02,  9.9909e-01, -1.0000e+00, -9.9989e-01,  9.9306e-01,\n",
       "         -9.9990e-01,  9.8171e-01,  9.9458e-01,  9.9910e-01, -1.2928e-01,\n",
       "          9.9981e-01,  9.9971e-01,  9.4773e-01, -2.6167e-01, -1.0000e+00,\n",
       "          7.9619e-01, -8.3579e-01, -9.9983e-01,  8.5071e-02, -2.0959e-01,\n",
       "         -9.9995e-01,  9.6484e-01, -1.9482e-01,  9.9997e-01,  1.6018e-01,\n",
       "         -9.9993e-01,  2.3277e-02,  2.1008e-01, -1.7639e-01,  9.9967e-01,\n",
       "          9.9993e-01,  1.7767e-01, -9.8356e-01,  5.8431e-02, -9.9437e-01,\n",
       "         -4.8473e-02,  9.9905e-01,  9.9982e-01, -9.9997e-01,  9.9992e-01,\n",
       "         -9.3099e-01, -1.2377e-01,  1.1999e-01, -9.9825e-01,  9.9875e-01,\n",
       "          9.6729e-03, -4.6642e-02,  1.0000e+00,  9.9975e-01, -1.6745e-01,\n",
       "         -9.9992e-01, -9.9804e-01,  9.9995e-01, -9.9855e-01,  3.0256e-01,\n",
       "          9.9999e-01,  9.6176e-01,  1.0000e+00,  9.9544e-01,  9.9996e-01,\n",
       "         -9.9996e-01, -3.6227e-01,  2.0460e-01, -9.9997e-01,  9.9966e-01,\n",
       "         -9.8876e-01, -5.9817e-01, -8.4976e-01, -1.5322e-01, -1.0636e-01,\n",
       "         -9.9997e-01,  1.2591e-01,  2.7995e-02, -9.9734e-01, -9.9048e-01,\n",
       "         -9.9985e-01, -9.9953e-01,  9.9648e-01,  6.6921e-01,  8.0580e-01,\n",
       "         -2.6967e-01,  1.5770e-01,  5.2538e-02, -9.9999e-01, -9.9985e-01,\n",
       "         -9.9969e-01,  6.8591e-01,  3.5948e-01,  9.9252e-01, -9.9953e-01,\n",
       "          9.9992e-01, -9.9979e-01,  9.9995e-01,  9.6590e-01, -4.7213e-02,\n",
       "         -6.0904e-01,  2.3965e-01, -9.9991e-01,  1.8076e-01, -1.0700e-01,\n",
       "          9.5916e-01,  9.9763e-01,  9.8082e-01, -7.6473e-01,  9.9998e-01,\n",
       "         -9.9821e-01,  9.5742e-01, -1.6378e-01,  9.9751e-01,  1.0000e+00,\n",
       "         -1.0000e+00,  2.1522e-01, -9.9999e-01,  2.2241e-01,  7.5109e-02,\n",
       "          9.9998e-01,  9.9604e-01,  9.9395e-01,  9.9996e-01, -8.9462e-01,\n",
       "         -9.9979e-01,  9.8582e-01, -9.9997e-01,  9.2536e-01,  1.0000e+00,\n",
       "         -2.8795e-02, -2.9501e-01,  9.9999e-01, -2.1041e-01,  9.9932e-01,\n",
       "         -1.3145e-01, -1.3375e-01, -9.9934e-01,  1.7716e-01,  8.5486e-01,\n",
       "          9.9623e-01, -9.9843e-01, -3.2110e-02,  9.8580e-01,  4.7530e-02,\n",
       "         -7.1364e-02, -9.9971e-01, -9.9995e-01,  9.9994e-01,  9.9983e-01,\n",
       "          8.3281e-01, -1.9843e-01,  1.0000e+00,  3.0434e-01,  9.9901e-01,\n",
       "         -5.7670e-02,  4.6264e-01, -3.0254e-01,  9.9887e-01,  1.6716e-01,\n",
       "          9.3370e-01,  1.0024e-01,  9.9999e-01, -3.9300e-01, -1.0000e+00,\n",
       "         -1.0407e-01,  9.2857e-01,  3.2425e-01, -9.9749e-01,  8.8768e-01,\n",
       "         -2.2917e-01,  9.9997e-01,  5.4940e-02, -8.4139e-01,  9.9163e-01,\n",
       "         -9.9995e-01,  8.1449e-01, -9.9999e-01, -9.9796e-01,  9.9999e-01,\n",
       "         -4.6683e-02, -1.0000e+00,  9.4259e-01,  9.9998e-01, -7.0940e-01,\n",
       "          9.7324e-01, -1.9192e-01, -9.9992e-01, -4.6551e-02, -2.1137e-01,\n",
       "         -1.0000e+00, -9.9052e-01, -1.0000e+00, -9.6008e-01,  1.5701e-02,\n",
       "          9.9022e-01, -9.9995e-01,  1.7404e-01, -9.9989e-01,  9.9235e-01,\n",
       "          9.9980e-01, -1.5061e-01, -1.3671e-01,  1.0000e+00, -9.0453e-01,\n",
       "          2.7068e-02, -9.3390e-01,  1.5655e-01, -9.0900e-02,  9.9938e-01,\n",
       "          2.2792e-01,  9.9921e-01, -9.9957e-01,  1.3366e-01,  9.7570e-01,\n",
       "         -9.9999e-01, -3.9493e-01,  9.5641e-01,  1.6681e-01,  6.7808e-02,\n",
       "         -1.9222e-01, -3.5963e-02,  6.5049e-01,  9.9971e-01,  1.0000e+00,\n",
       "          9.9783e-01,  1.0000e+00,  9.9998e-01,  5.9980e-02, -9.9848e-01,\n",
       "         -8.4595e-01, -7.9653e-02, -9.9999e-01, -9.0939e-01, -9.9980e-01,\n",
       "          9.7781e-01, -7.4939e-02,  1.0000e+00, -9.9999e-01,  1.0000e+00,\n",
       "         -9.7469e-01,  1.4370e-02, -7.9629e-02,  1.0239e-01, -1.1729e-03,\n",
       "         -1.2513e-01,  9.9903e-01,  2.4278e-01,  9.9822e-01,  9.9422e-01,\n",
       "          9.8852e-02, -1.0361e-01,  2.5417e-01, -9.5969e-02,  9.9929e-01,\n",
       "         -9.9607e-01,  9.9650e-01, -1.4456e-02,  9.9990e-01, -1.9201e-01,\n",
       "         -9.9996e-01,  9.9673e-01, -9.9995e-01, -3.5304e-01, -9.9995e-01,\n",
       "         -9.2829e-01, -9.8075e-02, -9.6901e-01, -1.8956e-01,  9.7906e-01,\n",
       "          2.5209e-01, -3.6027e-01, -1.0000e+00, -9.8124e-01,  9.5778e-01,\n",
       "          9.9986e-01, -9.9666e-01,  9.9900e-01,  9.9746e-01, -8.5908e-01,\n",
       "          4.2404e-01,  8.4787e-01, -9.9886e-01,  9.9229e-01, -9.9999e-01,\n",
       "         -3.4471e-02,  9.9176e-01, -1.3424e-02, -9.9984e-01, -9.5667e-01,\n",
       "         -5.6983e-02,  8.2463e-01, -2.8983e-01,  9.9999e-01, -6.8043e-03,\n",
       "          4.9902e-02, -9.9994e-01, -9.9634e-01, -6.7331e-01,  3.0349e-01,\n",
       "          9.9924e-01, -9.9998e-01,  2.3042e-01,  9.9867e-01, -9.9970e-01,\n",
       "         -3.9305e-01, -7.1880e-04,  1.1265e-01,  1.0499e-01, -9.9243e-01,\n",
       "         -9.9999e-01, -9.9990e-01,  1.0000e+00,  5.8995e-03, -1.0694e-01,\n",
       "          9.9934e-01,  9.9959e-01,  9.9987e-01, -9.9473e-01,  9.0058e-01,\n",
       "          9.9977e-01, -2.0776e-01,  8.1709e-02, -8.6469e-01, -1.2329e-01,\n",
       "         -7.2328e-01, -9.9283e-01,  2.0182e-01,  3.1300e-01, -8.4028e-01,\n",
       "         -9.9374e-01,  9.9997e-01,  9.9998e-01,  1.0000e+00, -6.6918e-02,\n",
       "         -9.7459e-01,  9.9381e-01, -9.8461e-01, -9.9929e-01, -1.1282e-01,\n",
       "          9.9977e-01, -9.9727e-01,  2.8564e-01, -7.4667e-01, -9.3307e-01,\n",
       "          9.9720e-01, -9.9992e-01, -8.1189e-02, -1.0000e+00, -9.9994e-01,\n",
       "         -9.9996e-01,  1.0000e+00,  5.7924e-02, -3.4014e-01, -9.9991e-01,\n",
       "          1.0000e+00,  9.2922e-01, -9.3877e-01, -1.0911e-01,  9.9997e-01,\n",
       "         -4.8812e-01, -8.8058e-01, -1.0000e+00, -9.9809e-01,  9.9802e-01,\n",
       "          1.2965e-01,  9.9999e-01,  5.4014e-01, -9.9713e-01,  6.1616e-01,\n",
       "          9.4263e-01, -7.8493e-02, -9.9961e-01, -9.9973e-01, -1.4163e-01,\n",
       "          5.8994e-02, -1.6550e-01, -1.1907e-01,  1.1718e-01,  9.9993e-01,\n",
       "         -5.8853e-02, -4.4854e-02, -1.9549e-01,  1.0000e+00, -3.2075e-02,\n",
       "         -9.9950e-01, -9.4754e-01, -6.6986e-03, -9.9149e-01, -9.8473e-01,\n",
       "         -9.9994e-01, -1.7109e-01,  1.5309e-01,  5.9967e-02, -9.7286e-01,\n",
       "         -9.9811e-01, -9.9966e-01, -5.5836e-02, -6.9526e-01, -9.8141e-01,\n",
       "         -5.9543e-02, -9.9302e-01, -9.9937e-01,  9.9988e-01, -9.9960e-01,\n",
       "         -1.2423e-01,  9.8230e-01,  9.9951e-01, -9.9974e-01,  1.4993e-01,\n",
       "          9.9776e-01, -9.9941e-01,  3.4747e-01, -9.1954e-01,  2.0305e-01,\n",
       "         -8.9859e-01, -9.9999e-01,  2.6863e-01,  9.9982e-01,  9.9987e-01,\n",
       "          9.9746e-01,  9.4303e-01, -8.4870e-01,  9.9005e-01,  9.9926e-01,\n",
       "          1.0000e+00,  1.2501e-01, -2.3212e-01, -9.9998e-01,  6.8693e-01,\n",
       "          9.4147e-01,  1.4294e-01,  8.9662e-01, -9.9990e-01,  3.0112e-01,\n",
       "         -8.0224e-01,  4.4111e-01,  1.0000e+00,  9.6334e-01, -2.4414e-02,\n",
       "         -9.9988e-01,  5.2228e-02, -5.6680e-01,  1.5751e-01, -9.9836e-01,\n",
       "         -3.6988e-02,  1.0000e+00, -9.9228e-01,  1.0529e-01, -9.9975e-01,\n",
       "         -9.9991e-01,  9.9737e-01, -9.9997e-01,  1.0000e+00,  9.9371e-01,\n",
       "         -9.9280e-01, -2.6344e-01, -9.7879e-01,  8.1649e-02, -1.3156e-01,\n",
       "         -1.4441e-01, -4.8694e-01, -1.6536e-01, -1.0000e+00, -1.8311e-01,\n",
       "          9.9220e-01, -4.0187e-02, -7.9344e-01, -9.9983e-01,  1.8055e-01,\n",
       "          9.5330e-01, -9.9934e-01, -9.9993e-01,  8.8169e-02, -2.0475e-01,\n",
       "          1.3701e-01,  7.7092e-01, -3.8089e-04,  4.3807e-02, -9.9500e-01,\n",
       "          1.1648e-01,  8.9230e-01, -9.6869e-01,  7.9067e-01, -7.3749e-01,\n",
       "         -8.3947e-01, -3.4445e-01,  9.9966e-01,  9.9995e-01, -9.9933e-01,\n",
       "         -9.9953e-01, -7.3645e-01, -5.0848e-02, -8.1060e-01,  9.9969e-01,\n",
       "         -1.9809e-01, -9.9836e-01,  3.4432e-02,  2.1799e-02, -5.0117e-02,\n",
       "         -9.6748e-01,  1.0000e+00, -9.9966e-01,  1.0000e+00, -9.9999e-01,\n",
       "         -9.9113e-01,  2.0731e-03,  9.9997e-01, -9.9999e-01, -7.9624e-02,\n",
       "          9.9993e-01, -1.0000e+00,  1.0312e-01, -9.1705e-01,  9.8390e-01,\n",
       "         -6.5253e-02, -6.4437e-02,  8.8219e-01, -9.9994e-01,  1.1050e-01,\n",
       "         -9.9944e-01,  9.1211e-01,  9.9811e-01, -9.9994e-01, -8.4206e-01,\n",
       "         -9.9992e-01,  2.1746e-02,  2.8865e-01, -9.9773e-01,  9.8982e-01,\n",
       "          9.9996e-01, -1.7795e-01,  9.6474e-01, -9.9987e-01,  3.2535e-02,\n",
       "         -1.5247e-01, -9.3132e-01,  3.4830e-02, -9.9984e-01,  9.1811e-01,\n",
       "         -9.9877e-01,  9.9355e-01, -1.0000e+00,  8.7116e-01,  9.9934e-01,\n",
       "         -7.4722e-02,  2.1285e-01, -9.4624e-02,  5.7058e-01, -9.9999e-01,\n",
       "         -3.0280e-01, -9.9996e-01, -9.9980e-01, -9.0533e-02,  9.9986e-01,\n",
       "          9.9313e-01,  1.3615e-01,  6.7833e-01, -9.9455e-01,  3.1724e-01,\n",
       "          3.5563e-01,  8.4191e-01,  9.9997e-01, -9.9990e-01, -9.9575e-01,\n",
       "          9.9885e-01, -9.9988e-01, -9.9367e-01,  1.0000e+00,  8.6774e-01,\n",
       "          9.9968e-01,  9.0155e-02, -9.9909e-01, -6.4762e-02,  2.6174e-02,\n",
       "          9.9981e-01,  1.8197e-01,  2.6745e-03,  9.9999e-01, -1.8482e-02,\n",
       "         -8.8507e-02, -7.5651e-01,  9.9638e-01, -3.3776e-03, -1.2047e-01,\n",
       "          9.9790e-01, -8.5212e-01, -9.9764e-01, -9.9989e-01, -1.7354e-02,\n",
       "         -1.9777e-01, -1.1437e-01, -1.6044e-01, -2.7838e-01,  1.0000e+00,\n",
       "         -9.9984e-01,  9.8339e-01, -9.9999e-01, -9.9994e-01,  2.2136e-01,\n",
       "          5.9865e-02,  9.9988e-01, -5.8379e-02, -9.7434e-01,  1.3491e-01,\n",
       "         -9.6239e-01,  9.9982e-01, -9.9983e-01,  8.7486e-01, -1.9846e-01,\n",
       "          2.3707e-01,  9.9992e-01,  9.9974e-01, -9.2951e-02, -9.9861e-01,\n",
       "         -7.4507e-01,  3.3211e-02, -9.9672e-01,  9.9972e-01, -1.2511e-01,\n",
       "         -1.3837e-02, -1.8230e-01,  3.6435e-02, -9.9995e-01, -9.9227e-01,\n",
       "          1.6219e-01,  9.9921e-01, -9.9999e-01,  8.0535e-01, -9.8600e-01,\n",
       "          9.9984e-01,  9.9992e-01,  1.0000e+00,  1.4184e-02,  9.9155e-01,\n",
       "         -9.9997e-01, -9.7469e-01,  9.9516e-01,  9.9907e-01,  9.9999e-01,\n",
       "          9.9877e-01,  9.9471e-01,  6.4378e-02, -9.9995e-01,  8.8705e-01,\n",
       "          1.3839e-01, -1.7139e-01, -1.6791e-01, -7.7329e-01, -9.9996e-01,\n",
       "          9.9995e-01, -9.9937e-01, -9.9998e-01, -9.5690e-01, -9.9998e-01,\n",
       "          9.9942e-01,  9.5924e-01,  9.9980e-01,  9.1993e-01, -9.9988e-01,\n",
       "         -9.9686e-01, -1.4503e-01, -9.6714e-01, -9.9878e-01,  7.0459e-02,\n",
       "         -1.0000e+00,  1.3142e-01,  1.9705e-01, -8.3304e-01,  1.7780e-01,\n",
       "         -7.2375e-01, -8.0249e-01,  9.9957e-01,  8.6662e-01,  9.6914e-01,\n",
       "         -9.3417e-01, -9.9503e-01,  4.2614e-02, -9.9989e-01,  9.8853e-01,\n",
       "          9.9995e-01, -2.6759e-01,  9.9273e-01, -8.9761e-01,  6.4622e-02,\n",
       "         -9.9993e-01, -1.0000e+00,  6.2294e-01,  9.9969e-01, -1.0584e-01,\n",
       "         -9.9992e-01, -1.1074e-01, -9.9900e-01, -1.1448e-01,  9.7409e-01,\n",
       "          9.9523e-01, -9.9989e-01,  9.9959e-01, -9.4421e-01,  2.1149e-01,\n",
       "          9.3318e-01, -9.9998e-01,  1.4993e-01, -9.7059e-01,  9.9994e-01,\n",
       "         -1.0000e+00,  9.6980e-01, -2.6445e-01,  5.8900e-02, -1.9099e-02,\n",
       "          9.2799e-01, -9.9927e-01, -1.0547e-01,  9.4886e-01,  9.6861e-01,\n",
       "         -8.3740e-02,  9.9688e-01,  2.0492e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"rbt3\")\n",
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state\n",
    "output.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 帶Model Head的模型呼叫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "clz_model = AutoModelForSequenceClassification.from_pretrained('rbt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[0.1899, 0.2663]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model(**inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
