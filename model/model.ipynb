{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型下載與保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 連線下載\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8647373c42fc49f0b6442b124fce8de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/755 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749f2749ebfd40eeb496cd1151b726dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/755 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e0ba80e4d94003817500d78d7d345e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/185M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('hfl/rbt4', force_download=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用git clone下載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正複製到 'rbt3'...\n",
      "remote: Enumerating objects: 48, done.\u001b[K\n",
      "remote: Total 48 (delta 0), reused 0 (delta 0), pack-reused 48 (from 1)\u001b[K\n",
      "展開物件中: 100% (48/48), 156.45 KiB | 1.08 MiB/s, 完成.\n",
      "過濾內容: 100% (3/3), 442.86 MiB | 12.46 MiB/s, 完成.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/hfl/rbt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('rbt4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"rbt4\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 4,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.45.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看模型參數\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"./rbt4\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 4,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.45.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#取出參數\n",
    "config = AutoConfig.from_pretrained('./rbt4')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型呼叫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2483, 2207, 4638, 2769,  738, 3300, 1920, 1918, 2682,  106,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = '弱小的我也有大夢想!'\n",
    "tokenizer = AutoTokenizer.from_pretrained('rbt4')\n",
    "inputs = tokenizer(sen, return_tensors='pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1571,  0.1157, -0.1746,  ...,  0.1085, -0.1736, -0.3024],\n",
       "         [-0.0919, -0.3945,  0.1082,  ...,  0.1022, -0.5488, -0.3210],\n",
       "         [ 0.2476,  0.0638, -0.3626,  ..., -0.4500,  0.1480, -0.4372],\n",
       "         ...,\n",
       "         [ 0.1361,  0.4644, -0.7512,  ...,  0.1637,  0.1197, -0.2751],\n",
       "         [ 0.4727, -0.0819, -1.0211,  ...,  0.1789,  0.0281, -0.4907],\n",
       "         [ 0.1570,  0.1157, -0.1745,  ...,  0.1084, -0.1736, -0.3024]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 9.7305e-02,  9.8785e-01, -5.8585e-01,  6.0877e-01, -2.1885e-02,\n",
       "          9.9489e-01, -9.7229e-01,  2.9337e-02,  1.0029e-02, -5.8181e-02,\n",
       "         -5.0308e-02, -9.7945e-01,  8.9820e-02,  8.4128e-02,  6.4013e-02,\n",
       "         -6.9489e-02,  6.6019e-02, -1.0562e-01,  5.5114e-02,  3.3327e-02,\n",
       "          9.6195e-01, -9.8599e-02,  4.0513e-02,  9.8646e-01,  9.6993e-01,\n",
       "          6.1760e-01,  1.1032e-01, -7.9383e-01, -9.9865e-01,  7.9728e-01,\n",
       "          3.1433e-02,  9.4975e-01,  6.0850e-02, -9.9880e-01, -1.9556e-01,\n",
       "          3.5792e-02,  2.2983e-02,  3.5759e-02,  7.3159e-02, -3.4606e-02,\n",
       "         -1.1390e-01,  2.2986e-01,  6.3857e-02,  8.1494e-01,  8.9345e-02,\n",
       "          9.0025e-02, -9.4469e-01, -1.4529e-01, -8.0438e-02,  9.9857e-01,\n",
       "         -9.0396e-02, -2.4631e-01, -9.2998e-01,  9.8141e-01, -9.6849e-01,\n",
       "          8.7423e-02, -1.1230e-01,  9.7023e-02,  9.9959e-01,  9.6383e-01,\n",
       "          1.4336e-01, -8.9549e-02,  9.9453e-01, -9.6718e-01,  3.6358e-02,\n",
       "         -1.1453e-01,  2.1815e-02,  5.7614e-01,  9.9954e-01,  9.9169e-01,\n",
       "          9.7658e-01,  8.2821e-01,  9.8896e-01, -3.0093e-01, -9.1382e-02,\n",
       "         -9.7783e-01,  3.8205e-01,  1.8098e-01, -9.8299e-01,  2.6085e-02,\n",
       "          9.9847e-01, -8.6703e-01, -5.4261e-02,  4.8147e-01, -6.9038e-02,\n",
       "         -9.5483e-01,  1.0330e-01, -4.6514e-02, -3.1672e-02, -8.1308e-02,\n",
       "          9.9850e-01, -8.4920e-01, -9.4076e-02,  5.4674e-01,  1.1958e-02,\n",
       "          1.5031e-01, -1.3629e-01,  1.8074e-02,  5.2310e-02,  8.6522e-01,\n",
       "         -8.6261e-03,  4.2422e-02, -1.2230e-01,  6.9969e-01,  2.4251e-01,\n",
       "          5.6092e-02,  3.0843e-02, -8.1875e-02,  2.0615e-01,  3.2628e-02,\n",
       "         -9.9931e-01, -7.9616e-02,  9.5309e-01, -2.4762e-01, -1.2229e-01,\n",
       "          9.6445e-01,  6.0695e-02,  4.7043e-02,  3.3749e-02, -1.5100e-01,\n",
       "          1.5325e-01, -1.3184e-01, -9.9235e-01,  3.2911e-01, -8.1429e-03,\n",
       "          9.7240e-01,  8.2680e-01, -9.8823e-01, -9.8258e-01, -4.6314e-03,\n",
       "         -4.9532e-02,  2.5505e-01,  2.1636e-01,  1.9546e-01,  5.2838e-01,\n",
       "          5.7883e-02,  1.8650e-02, -7.3733e-02,  9.9767e-01,  9.4941e-02,\n",
       "          1.7785e-01,  7.4387e-02,  9.9594e-01, -6.4835e-02,  9.2435e-01,\n",
       "         -5.1152e-01,  8.1438e-02, -2.1100e-02,  7.4665e-02,  9.6786e-01,\n",
       "         -4.8655e-02,  5.8236e-02, -7.2225e-02,  9.9899e-01, -9.9135e-01,\n",
       "         -4.3498e-01, -4.7244e-02,  9.5709e-01, -1.3037e-01,  1.7224e-02,\n",
       "          7.9384e-01, -9.7104e-01, -3.1101e-02,  3.3747e-02, -9.9561e-01,\n",
       "          9.6360e-01, -1.9714e-02,  9.9965e-01,  2.0043e-01, -9.7033e-01,\n",
       "         -5.7403e-01,  2.8060e-02, -2.2158e-02, -7.6979e-01, -2.6868e-01,\n",
       "          4.7266e-01, -2.3111e-02,  7.0020e-02,  6.7465e-02,  1.3771e-02,\n",
       "          9.1917e-01, -3.0783e-02, -9.9647e-01,  1.1301e-01, -1.0099e-02,\n",
       "          9.7278e-01,  4.1265e-01,  3.9256e-02,  1.6113e-01,  1.7646e-01,\n",
       "         -9.6717e-02, -6.7038e-02, -9.7713e-02, -3.4587e-01,  7.9925e-01,\n",
       "          9.9215e-03, -3.2264e-02, -9.2679e-01, -9.1050e-01, -6.3937e-02,\n",
       "          9.8885e-01, -6.9790e-02, -9.4946e-02,  7.3791e-01, -7.1376e-02,\n",
       "          1.0172e-01, -4.6134e-02,  5.5065e-01, -9.1373e-01, -6.9891e-01,\n",
       "         -3.6209e-03, -1.7648e-02, -8.6823e-02,  1.3515e-01, -9.8263e-02,\n",
       "         -2.3611e-02, -2.3009e-01,  3.1498e-01,  1.3346e-01,  9.9020e-01,\n",
       "         -7.8597e-01, -1.3342e-01, -9.9698e-01,  8.8911e-01, -9.8567e-01,\n",
       "         -8.8924e-01,  9.9151e-01,  9.7727e-01,  1.3667e-01,  8.4420e-01,\n",
       "          9.8925e-01, -9.7315e-01,  8.2248e-01, -9.9948e-01,  7.7698e-01,\n",
       "         -8.8512e-01, -5.4641e-01,  1.0525e-01, -7.6061e-01,  9.7448e-01,\n",
       "          9.7213e-01,  1.6567e-01,  7.7555e-02, -7.4731e-01, -1.8532e-02,\n",
       "         -2.0021e-02,  1.0833e-01,  8.4080e-02, -7.3122e-02, -3.0343e-01,\n",
       "         -9.9177e-01, -1.6334e-04, -6.2602e-02, -8.7682e-01, -9.9676e-01,\n",
       "         -4.4652e-02,  6.6200e-01,  1.5293e-01,  1.2724e-03,  1.4810e-02,\n",
       "         -9.8402e-01, -1.3232e-02,  9.9965e-01, -8.0264e-01,  1.4690e-01,\n",
       "          6.6630e-03,  1.2409e-01, -8.3924e-01,  5.1159e-03, -9.8627e-01,\n",
       "          1.2538e-01,  1.3841e-01, -9.9859e-01, -1.5269e-02, -4.4457e-02,\n",
       "          9.8559e-01,  1.1759e-02, -9.9261e-01,  9.8260e-01,  9.9468e-01,\n",
       "         -6.4658e-01, -9.9949e-01, -4.2017e-01,  9.8194e-01, -2.8779e-01,\n",
       "          1.9968e-01,  4.2267e-01, -1.7438e-01,  5.9470e-02, -7.4975e-01,\n",
       "          9.6076e-02, -6.4016e-01,  6.8948e-03,  9.3584e-02,  9.9930e-01,\n",
       "          1.9704e-01,  9.6777e-01,  1.9808e-02, -8.7099e-02, -7.1398e-01,\n",
       "         -3.8453e-02,  9.1337e-01, -9.9287e-01, -6.9453e-02,  8.8688e-01,\n",
       "          5.1319e-03,  6.0339e-02, -4.5720e-01,  6.2888e-03,  9.8817e-02,\n",
       "          4.3052e-02, -9.6517e-02,  9.9675e-01,  9.9188e-01,  9.6928e-01,\n",
       "          1.3052e-01, -9.5196e-01,  7.4335e-01, -9.0350e-01,  5.0586e-02,\n",
       "         -7.8810e-01, -9.0202e-01,  4.4028e-02,  4.8461e-02,  1.0843e-01,\n",
       "         -8.4375e-01,  9.9566e-01, -4.3956e-02,  3.9417e-02,  9.4986e-01,\n",
       "         -7.7788e-01,  8.8933e-03,  1.7650e-01, -2.5450e-02, -8.2621e-02,\n",
       "         -1.0028e-02, -9.6907e-01,  1.1500e-02,  5.5882e-01,  1.0753e-01,\n",
       "         -9.7347e-03, -1.8842e-01,  9.4585e-01, -4.5001e-01, -2.2996e-01,\n",
       "         -7.1241e-01,  1.2975e-01,  1.7881e-01, -6.6060e-02, -1.4757e-01,\n",
       "         -7.8794e-02,  9.8611e-01,  1.3777e-01,  6.0887e-02,  1.9148e-01,\n",
       "         -6.5313e-01,  9.7201e-01,  3.9382e-02,  9.5947e-01,  9.2770e-02,\n",
       "          2.2607e-01,  9.4932e-01,  9.5755e-01, -2.7511e-01, -1.0350e-01,\n",
       "          9.1387e-02,  3.6979e-02, -9.9713e-01, -5.5748e-01,  4.3631e-02,\n",
       "         -7.2343e-02, -7.7544e-02,  1.3783e-02,  9.7164e-01, -5.4003e-01,\n",
       "          1.1413e-01, -3.0920e-02,  4.8927e-02, -2.5038e-03,  4.4041e-02,\n",
       "         -5.5654e-02, -8.2601e-01, -9.4381e-02, -1.8086e-02, -7.6715e-01,\n",
       "          3.2351e-01,  9.9825e-01, -9.9884e-01,  1.3126e-01, -6.9004e-02,\n",
       "         -1.6718e-01,  9.7558e-01, -8.8600e-02,  6.6390e-02, -2.9446e-02,\n",
       "         -9.9860e-01, -2.3678e-01,  9.0776e-02,  9.3621e-01,  8.3935e-02,\n",
       "          9.9828e-01,  8.3279e-03,  2.8556e-01, -9.9557e-01, -9.9742e-01,\n",
       "         -6.2294e-01, -1.0785e-01, -8.0241e-03,  7.5521e-01,  1.4645e-01,\n",
       "         -5.8055e-02,  8.2897e-03,  9.9414e-01,  1.2737e-01, -9.5241e-01,\n",
       "          1.3468e-01,  6.8839e-02, -5.9732e-01, -7.7528e-01,  1.2901e-01,\n",
       "          9.5270e-03,  9.4936e-01, -1.0436e-03,  9.0554e-01, -8.0806e-02,\n",
       "          4.8804e-01, -7.9345e-02,  5.1972e-01, -1.6412e-01, -2.1580e-01,\n",
       "          1.2000e-01,  9.7915e-01, -1.0263e-01, -1.2248e-01, -8.1038e-03,\n",
       "         -7.8568e-02, -8.4284e-02, -2.4836e-03, -3.4590e-02, -2.3102e-01,\n",
       "         -9.9606e-01, -1.1623e-01,  9.7870e-02,  2.9217e-02,  8.6688e-02,\n",
       "          1.2859e-01,  5.3058e-02,  9.7169e-01,  9.2310e-01, -2.5965e-01,\n",
       "          9.0603e-01,  9.9936e-01, -7.2735e-02, -4.3027e-02,  8.4461e-02,\n",
       "          6.7118e-03,  5.4385e-02,  9.8964e-01,  1.4329e-01, -1.8420e-01,\n",
       "          9.9800e-01,  8.3510e-01, -8.6319e-01, -9.9037e-01, -6.8443e-01,\n",
       "          2.4529e-01,  8.6299e-01,  6.7452e-03,  2.5430e-03, -4.8691e-02,\n",
       "         -1.7390e-01,  2.1053e-02, -8.9469e-01, -1.6403e-01,  2.7991e-02,\n",
       "         -3.0164e-02, -7.5017e-01, -6.2170e-02,  5.6520e-02,  9.9865e-01,\n",
       "          9.8966e-01, -9.6519e-01, -7.9775e-02,  7.2175e-02,  1.6517e-01,\n",
       "          4.7486e-02, -1.2400e-01, -9.9820e-01, -6.3065e-02,  4.0894e-02,\n",
       "          9.9942e-01, -7.9206e-01,  5.7532e-02,  9.1537e-01, -3.1523e-02,\n",
       "          2.0677e-01, -6.5194e-01,  7.1037e-02, -9.7110e-01,  9.8136e-02,\n",
       "          9.8445e-01, -9.9854e-01, -7.3372e-02, -1.9880e-02,  9.5195e-01,\n",
       "          3.9645e-02,  7.7587e-02,  7.7785e-01, -4.5688e-01,  9.8913e-03,\n",
       "         -1.2627e-01, -5.9523e-02,  9.7842e-01,  3.3728e-02, -9.9885e-01,\n",
       "          4.3758e-01, -1.1388e-02, -8.0762e-01, -3.2207e-02, -3.3426e-02,\n",
       "         -6.1047e-03,  3.3376e-02,  8.0054e-01, -1.2545e-01,  9.9961e-01,\n",
       "          8.7464e-01,  2.2735e-02,  7.3260e-02, -9.8072e-02, -5.7563e-03,\n",
       "         -2.0925e-02, -9.0591e-02, -3.8772e-02,  8.8877e-01,  1.5822e-01,\n",
       "         -9.2697e-01, -8.3003e-01, -3.6445e-02,  9.9043e-01,  9.9971e-01,\n",
       "          9.9616e-01, -9.6277e-01, -6.1358e-02,  4.3992e-02,  7.4795e-01,\n",
       "          5.9263e-02,  1.1810e-02,  1.5230e-02,  3.7280e-02,  9.9363e-01,\n",
       "          1.3888e-01, -4.2662e-02, -8.2995e-02, -7.7338e-01,  1.6234e-02,\n",
       "          1.3693e-01, -6.5838e-02, -9.9935e-01,  9.8558e-01, -9.8101e-01,\n",
       "         -4.3536e-02,  7.6727e-02,  8.4219e-01, -9.2257e-01,  8.6285e-01,\n",
       "          1.9054e-02,  6.7411e-02,  6.0243e-01, -2.5377e-01,  1.9298e-02,\n",
       "          9.3375e-01,  1.2640e-02,  9.9154e-01, -1.7085e-02, -8.0466e-01,\n",
       "          9.9650e-01,  2.6386e-02, -9.7641e-01,  9.9385e-01, -7.9880e-01,\n",
       "         -8.8252e-02,  3.1297e-01,  9.8839e-01, -4.1561e-02,  9.7017e-01,\n",
       "          6.1255e-01, -6.9062e-02, -9.9926e-01,  1.0783e-01, -1.5385e-01,\n",
       "          1.6908e-01, -4.4075e-03,  7.2799e-04, -1.1484e-01,  3.0030e-01,\n",
       "          1.0639e-01, -7.3313e-02, -4.7737e-01,  1.3817e-01,  8.9547e-01,\n",
       "          7.1329e-02, -9.9214e-01, -7.8818e-01,  2.3985e-01, -6.9908e-01,\n",
       "         -9.0795e-02, -9.0162e-01, -9.9869e-01,  1.1619e-01, -1.0112e-01,\n",
       "         -8.6900e-01, -5.6641e-02, -9.9966e-01, -1.5721e-01, -9.7857e-01,\n",
       "         -6.0270e-02, -7.9863e-03,  3.2623e-02, -1.0976e-01,  8.8299e-01,\n",
       "         -1.2324e-01,  6.6049e-01,  7.9367e-02,  6.7548e-01, -2.2346e-02,\n",
       "         -8.0150e-02,  9.8537e-01,  9.9960e-01,  3.8962e-01, -7.1785e-03,\n",
       "         -1.6346e-02,  2.1046e-02,  8.3179e-01, -1.4084e-01,  6.8481e-04,\n",
       "         -7.1911e-02,  9.9084e-01,  8.4351e-01,  8.9631e-02, -1.9365e-01,\n",
       "          9.1092e-01,  6.0653e-02, -9.7083e-01, -8.8985e-01,  9.7966e-01,\n",
       "         -9.9752e-01, -2.5592e-01,  9.9477e-01,  9.6770e-01,  9.9882e-01,\n",
       "         -8.7368e-01, -2.0690e-02, -4.5443e-02,  1.8999e-01, -9.8114e-01,\n",
       "         -9.0880e-01,  3.1935e-02,  1.9578e-01,  9.1684e-01, -7.2262e-01,\n",
       "          2.8978e-02, -1.5230e-01, -9.8208e-01,  2.0851e-02,  1.6707e-01,\n",
       "         -7.3464e-02,  1.4280e-01, -1.2405e-02, -9.5788e-01,  9.4639e-01,\n",
       "         -1.3286e-01, -9.9606e-01,  5.9739e-02, -1.2150e-02, -5.0695e-01,\n",
       "          2.7200e-01,  3.7637e-03, -2.1518e-01,  8.5315e-01, -9.5540e-01,\n",
       "          2.1024e-01, -4.4123e-02, -9.9852e-01, -3.7437e-02,  2.6749e-02,\n",
       "         -9.9735e-01,  4.4507e-02,  9.9947e-01,  9.3325e-01, -8.0686e-02,\n",
       "         -1.3694e-01,  9.9886e-01, -6.5844e-01,  9.7510e-01,  8.5505e-01,\n",
       "          9.2039e-01, -1.7758e-02,  2.2528e-01, -2.2833e-02,  1.1376e-01,\n",
       "         -9.9946e-01, -8.4238e-03,  9.8907e-01, -1.5677e-01, -2.9701e-02,\n",
       "          1.0995e-01,  1.9639e-01, -1.7561e-01,  9.2068e-01, -5.9950e-02,\n",
       "         -7.4977e-02,  5.4392e-02, -1.4153e-01, -9.7046e-01, -9.6737e-01,\n",
       "          9.8296e-01,  1.1676e-01,  6.0071e-02,  5.1146e-02, -3.7982e-01,\n",
       "          9.1772e-01, -1.4253e-01,  4.0442e-01,  3.6276e-03,  5.2157e-02,\n",
       "          1.3793e-01,  9.9832e-01,  8.2445e-03,  9.9819e-01, -1.3958e-01,\n",
       "         -8.5310e-02,  9.2030e-01, -8.1093e-02, -9.3646e-01, -9.8872e-01,\n",
       "          7.3373e-01, -9.8669e-01, -9.9579e-01,  8.9304e-01,  1.1119e-01,\n",
       "         -1.1828e-01,  9.9800e-01,  2.1329e-02,  8.9952e-01,  9.4535e-01,\n",
       "          5.1263e-01, -2.3209e-02,  5.1660e-01,  8.6156e-01, -9.9937e-01,\n",
       "          5.3145e-01,  9.9712e-01, -8.0118e-01,  1.7174e-01, -1.3804e-03,\n",
       "         -9.7733e-01, -9.6802e-01, -7.8687e-01, -7.6507e-01, -5.2744e-03,\n",
       "         -2.1729e-02,  9.4870e-01,  6.3016e-02, -2.0204e-01, -8.4631e-01,\n",
       "          1.6040e-02, -7.3254e-02,  7.3276e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"rbt4\")\n",
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state\n",
    "output.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 帶Model Head的模型呼叫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at rbt4 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "clz_model = AutoModelForSequenceClassification.from_pretrained('rbt4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.3032, -0.3222]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clz_model(**inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingFace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
