{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'case_id', 'duration_seconds', 'last_screen', 'device', 'ethn_hispanic', 'ethn_white', 'ethn_afr_american', 'ethn_asian', 'ethn_sth_else', 'ethn_prefer_not', 'age', 'education', 'english_fl', 'twitter_use', 'socmedia_use', 'prolific_hours', 'task_fun', 'task_interesting', 'task_boring', 'task_repetitive', 'task_important', 'task_depressing', 'task_offensive', 'repeat_tweet_coding', 'repeat_hs_coding', 'target_online_harassment', 'target_other_harassment', 'party_affiliation', 'societal_relevance_hs', 'annotator_id', 'condition', 'tweet_batch', 'hate_speech', 'offensive_language', 'tweet_id', 'orig_label_hs', 'orig_label_ol', 'orig_label_ne', 'tweet_hashed'],\n",
       "    num_rows: 89150\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset,DatasetDict\n",
    "\n",
    "datasets = load_dataset('soda-lmu/tweet-annotation-sensitivity-2')\n",
    "dataset = datasets['train']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'case_id', 'duration_seconds', 'last_screen', 'device', 'ethn_hispanic', 'ethn_white', 'ethn_afr_american', 'ethn_asian', 'ethn_sth_else', 'ethn_prefer_not', 'age', 'education', 'english_fl', 'twitter_use', 'socmedia_use', 'prolific_hours', 'task_fun', 'task_interesting', 'task_boring', 'task_repetitive', 'task_important', 'task_depressing', 'task_offensive', 'repeat_tweet_coding', 'repeat_hs_coding', 'target_online_harassment', 'target_other_harassment', 'party_affiliation', 'societal_relevance_hs', 'annotator_id', 'condition', 'tweet_batch', 'hate_speech', 'offensive_language', 'tweet_id', 'orig_label_hs', 'orig_label_ol', 'orig_label_ne', 'tweet_hashed'],\n",
       "    num_rows: 17830\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_dict = dataset.train_test_split(test_size=0.2,seed=42)\n",
    "test_dataset = another_dict['test']\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'case_id', 'duration_seconds', 'last_screen', 'device', 'ethn_hispanic', 'ethn_white', 'ethn_afr_american', 'ethn_asian', 'ethn_sth_else', 'ethn_prefer_not', 'age', 'education', 'english_fl', 'twitter_use', 'socmedia_use', 'prolific_hours', 'task_fun', 'task_interesting', 'task_boring', 'task_repetitive', 'task_important', 'task_depressing', 'task_offensive', 'repeat_tweet_coding', 'repeat_hs_coding', 'target_online_harassment', 'target_other_harassment', 'party_affiliation', 'societal_relevance_hs', 'annotator_id', 'condition', 'tweet_batch', 'hate_speech', 'offensive_language', 'tweet_id', 'orig_label_hs', 'orig_label_ol', 'orig_label_ne', 'tweet_hashed'],\n",
       "        num_rows: 8915\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'case_id', 'duration_seconds', 'last_screen', 'device', 'ethn_hispanic', 'ethn_white', 'ethn_afr_american', 'ethn_asian', 'ethn_sth_else', 'ethn_prefer_not', 'age', 'education', 'english_fl', 'twitter_use', 'socmedia_use', 'prolific_hours', 'task_fun', 'task_interesting', 'task_boring', 'task_repetitive', 'task_important', 'task_depressing', 'task_offensive', 'repeat_tweet_coding', 'repeat_hs_coding', 'target_online_harassment', 'target_other_harassment', 'party_affiliation', 'societal_relevance_hs', 'annotator_id', 'condition', 'tweet_batch', 'hate_speech', 'offensive_language', 'tweet_id', 'orig_label_hs', 'orig_label_ol', 'orig_label_ne', 'tweet_hashed'],\n",
       "        num_rows: 8915\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_test_dict = test_dataset.train_test_split(test_size=0.5,seed=42)\n",
    "validation_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'case_id', 'duration_seconds', 'last_screen', 'device', 'ethn_hispanic', 'ethn_white', 'ethn_afr_american', 'ethn_asian', 'ethn_sth_else', 'ethn_prefer_not', 'age', 'education', 'english_fl', 'twitter_use', 'socmedia_use', 'prolific_hours', 'task_fun', 'task_interesting', 'task_boring', 'task_repetitive', 'task_important', 'task_depressing', 'task_offensive', 'repeat_tweet_coding', 'repeat_hs_coding', 'target_online_harassment', 'target_other_harassment', 'party_affiliation', 'societal_relevance_hs', 'annotator_id', 'condition', 'tweet_batch', 'hate_speech', 'offensive_language', 'tweet_id', 'orig_label_hs', 'orig_label_ol', 'orig_label_ne', 'tweet_hashed'],\n",
       "        num_rows: 71320\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'case_id', 'duration_seconds', 'last_screen', 'device', 'ethn_hispanic', 'ethn_white', 'ethn_afr_american', 'ethn_asian', 'ethn_sth_else', 'ethn_prefer_not', 'age', 'education', 'english_fl', 'twitter_use', 'socmedia_use', 'prolific_hours', 'task_fun', 'task_interesting', 'task_boring', 'task_repetitive', 'task_important', 'task_depressing', 'task_offensive', 'repeat_tweet_coding', 'repeat_hs_coding', 'target_online_harassment', 'target_other_harassment', 'party_affiliation', 'societal_relevance_hs', 'annotator_id', 'condition', 'tweet_batch', 'hate_speech', 'offensive_language', 'tweet_id', 'orig_label_hs', 'orig_label_ol', 'orig_label_ne', 'tweet_hashed'],\n",
       "        num_rows: 8915\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'case_id', 'duration_seconds', 'last_screen', 'device', 'ethn_hispanic', 'ethn_white', 'ethn_afr_american', 'ethn_asian', 'ethn_sth_else', 'ethn_prefer_not', 'age', 'education', 'english_fl', 'twitter_use', 'socmedia_use', 'prolific_hours', 'task_fun', 'task_interesting', 'task_boring', 'task_repetitive', 'task_important', 'task_depressing', 'task_offensive', 'repeat_tweet_coding', 'repeat_hs_coding', 'target_online_harassment', 'target_other_harassment', 'party_affiliation', 'societal_relevance_hs', 'annotator_id', 'condition', 'tweet_batch', 'hate_speech', 'offensive_language', 'tweet_id', 'orig_label_hs', 'orig_label_ol', 'orig_label_ne', 'tweet_hashed'],\n",
       "        num_rows: 8915\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_3kind = DatasetDict({\n",
    "    \"train\": another_dict['train'],\n",
    "    \"validation\": validation_test_dict['train'],\n",
    "    \"test\": validation_test_dict['test']\n",
    "})\n",
    "\n",
    "datasets_3kind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@###### I'll show up and chug a beer or 8\",\n",
       " \"Reading the ut sexual assault case takes me back 2 college.I'll never forget D Walk would say dont run trains on them hoes.Straight Trouble\",\n",
       " '@###### Aww y u so mad tho, a successful man LMFAO, hut hugging as faggot.',\n",
       " \"The people who have historically been called white trash were called that for a reason. They're white trash. The truth hurts.\",\n",
       " \"The family of Ron O'Neal needs to sue Wu-Tang for that trash song they released in his name.\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = datasets_3kind['test']\n",
    "test_dataset['tweet_hashed'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff84c4173d784b899fa454a930e4070c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/8856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26a133e6cd540248f50cfae808c04a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"prefix:@###### I'll show up and chug a beer or 8\",\n",
       " \"prefix:Reading the ut sexual assault case takes me back 2 college.I'll never forget D Walk would say dont run trains on them hoes.Straight Trouble\",\n",
       " 'prefix:@###### Aww y u so mad tho, a successful man LMFAO, hut hugging as faggot.',\n",
       " \"prefix:The people who have historically been called white trash were called that for a reason. They're white trash. The truth hurts.\",\n",
       " \"prefix:The family of Ron O'Neal needs to sue Wu-Tang for that trash song they released in his name.\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_prefix(example):    \n",
    "    example['tweet_hashed'] = \"prefix:\" + example['tweet_hashed']\n",
    "    return example\n",
    "   \n",
    "#因為tweet_hashed有None,先清理資料\n",
    "test_dataset = test_dataset.filter(lambda example: example['tweet_hashed'] is not None)\n",
    "prefix_test_dataset = test_dataset.map(add_prefix)\n",
    "prefix_test_dataset['tweet_hashed'][:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, 3.0, 5.0, 4.0, 4.0]\n",
      "[\"@###### I'll show up and chug a beer or 8\", \"Reading the ut sexual assault case takes me back 2 college.I'll never forget D Walk would say dont run trains on them hoes.Straight Trouble\", '@###### Aww y u so mad tho, a successful man LMFAO, hut hugging as faggot.', \"The people who have historically been called white trash were called that for a reason. They're white trash. The truth hurts.\", \"The family of Ron O'Neal needs to sue Wu-Tang for that trash song they released in his name.\"]\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset['education'][:5])\n",
    "print(test_dataset['tweet_hashed'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5306969e93554e448b4cdf75dbbad546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215a488fc3c344c3bc54a04e21b068e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8915 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cce61927414caea5fbb97a5b4b601a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8915 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'case_id', 'duration_seconds', 'last_screen', 'device', 'ethn_hispanic', 'ethn_white', 'ethn_afr_american', 'ethn_asian', 'ethn_sth_else', 'ethn_prefer_not', 'age', 'education', 'english_fl', 'twitter_use', 'socmedia_use', 'prolific_hours', 'task_fun', 'task_interesting', 'task_boring', 'task_repetitive', 'task_important', 'task_depressing', 'task_offensive', 'repeat_tweet_coding', 'repeat_hs_coding', 'target_online_harassment', 'target_other_harassment', 'party_affiliation', 'societal_relevance_hs', 'annotator_id', 'condition', 'tweet_batch', 'hate_speech', 'offensive_language', 'tweet_id', 'orig_label_hs', 'orig_label_ol', 'orig_label_ne', 'tweet_hashed'],\n",
       "        num_rows: 71320\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'case_id', 'duration_seconds', 'last_screen', 'device', 'ethn_hispanic', 'ethn_white', 'ethn_afr_american', 'ethn_asian', 'ethn_sth_else', 'ethn_prefer_not', 'age', 'education', 'english_fl', 'twitter_use', 'socmedia_use', 'prolific_hours', 'task_fun', 'task_interesting', 'task_boring', 'task_repetitive', 'task_important', 'task_depressing', 'task_offensive', 'repeat_tweet_coding', 'repeat_hs_coding', 'target_online_harassment', 'target_other_harassment', 'party_affiliation', 'societal_relevance_hs', 'annotator_id', 'condition', 'tweet_batch', 'hate_speech', 'offensive_language', 'tweet_id', 'orig_label_hs', 'orig_label_ol', 'orig_label_ne', 'tweet_hashed'],\n",
       "        num_rows: 8915\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'case_id', 'duration_seconds', 'last_screen', 'device', 'ethn_hispanic', 'ethn_white', 'ethn_afr_american', 'ethn_asian', 'ethn_sth_else', 'ethn_prefer_not', 'age', 'education', 'english_fl', 'twitter_use', 'socmedia_use', 'prolific_hours', 'task_fun', 'task_interesting', 'task_boring', 'task_repetitive', 'task_important', 'task_depressing', 'task_offensive', 'repeat_tweet_coding', 'repeat_hs_coding', 'target_online_harassment', 'target_other_harassment', 'party_affiliation', 'societal_relevance_hs', 'annotator_id', 'condition', 'tweet_batch', 'hate_speech', 'offensive_language', 'tweet_id', 'orig_label_hs', 'orig_label_ol', 'orig_label_ne', 'tweet_hashed'],\n",
       "        num_rows: 8915\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_prefix1(example): \n",
    "    if example['education'] is not None and example['tweet_hashed'] is not None:   \n",
    "        example['tweet_hashed'] = \"prefix:\" + example['tweet_hashed']\n",
    "    return example\n",
    "\n",
    "datasets_3kind.map(add_prefix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18a4e1c91fa49359cd3032df71f7244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e351dc6fc474e02bfd4200796e1207f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-5ee7db9c6d3de01c.parquet:   0%|          | 0.00/8.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220fce5d97824422ab61ed4762dee89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'text'],\n",
       "        num_rows: 9827\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset,DatasetDict\n",
    "\n",
    "datasets = load_dataset('erhwenkuo/wikinews-zhtw')\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a8cba146ab48feb154efb04d131a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9827 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9827\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')\n",
    "def preprocess_func(example):      \n",
    "    model_inputs = tokenizer(example['text'], max_length=512, truncation=True)\n",
    "    model_inputs['labels'] = tokenizer(example['title'], max_length=200, truncation=True) \n",
    "    return model_inputs\n",
    "    \n",
    "\n",
    "datasets.map(preprocess_func,remove_columns=datasets['train'].column_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
