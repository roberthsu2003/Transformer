{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上傳至Huggingface\n",
    "- d-dev.json是validation\n",
    "- d-tran.json是train\n",
    "- test1.0.json是test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': ['男：你今天晚上有時間嗎?我們一起去看電影吧? 女：你喜歡恐怖片和愛情片，但是我喜歡喜劇片，科幻片一般。所以……', '男：足球比賽是明天上午八點開始吧? 女：因為天氣不好，比賽改到後天下午三點了。', '女：今天下午的討論會開得怎麼樣? 男：我覺得發言的人太少了。'], 'question': ['女的最喜歡哪種電影?', '根據對話，可以知道什麼?', '關於這次討論會，我們可以知道什麼?'], 'choices': [['恐怖片', '愛情片', '喜劇片', '科幻片'], ['今天天氣不好', '比賽時間變了', '校長忘了時間'], ['會是昨天開的', '男的沒有參加', '討論得不熱烈', '參加的人很少']], 'answer': ['喜劇片', '比賽時間變了', '討論得不熱烈']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def create_dataset(data):\n",
    "    \"\"\"Transforms the nested list structure into a list of dictionaries.\"\"\"\n",
    "    processed_data = []\n",
    "    for item in data:\n",
    "        context, questions, _ = item\n",
    "        for question_data in questions:\n",
    "            question = question_data[\"question\"]\n",
    "            choices = question_data[\"choice\"]\n",
    "            answer = question_data[\"answer\"]\n",
    "            processed_item = {\n",
    "                \"context\": \" \".join(context),  # Join context sentences\n",
    "                \"question\": question,\n",
    "                \"choices\": choices,\n",
    "                \"answer\": answer               \n",
    "            }\n",
    "            processed_data.append(processed_item)\n",
    "    return processed_data\n",
    "\n",
    "train_data = load_json('c3_tw/d-train.json')\n",
    "dev_data = load_json('c3_tw/d-dev.json')\n",
    "\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = Dataset.from_list(create_dataset(train_data))\n",
    "dev_dataset = Dataset.from_list(create_dataset(dev_data))\n",
    "\n",
    "\n",
    "# Create DatasetDict\n",
    "datasets = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": dev_dataset,\n",
    "})\n",
    "\n",
    "# Print the first few examples to verify the structure\n",
    "print(datasets[\"train\"][:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e38184217cf441bac353f83e068955a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8191ee02e5cf41d39bcf3ea40b3d5271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217b7003dbd54f1dad167ba2e5e19a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736e9df3b35448c38e18038dbc000e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e75758882224c329a0e0a1977d76e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47382bb7f3747878f95d011f00564bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/542 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/roberthsu2003/for_Multiple_Choice/commit/340b155fac6ea4e01bf19990eef48edf6992688b', commit_message='Upload dataset', commit_description='', oid='340b155fac6ea4e01bf19990eef48edf6992688b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/roberthsu2003/for_Multiple_Choice', endpoint='https://huggingface.co', repo_type='dataset', repo_id='roberthsu2003/for_Multiple_Choice'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, notebook_login\n",
    "api = HfApi()\n",
    "notebook_login() #this is likely needed for authentication\n",
    "datasets.push_to_hub('roberthsu2003/for_Multiple_Choice',private=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
