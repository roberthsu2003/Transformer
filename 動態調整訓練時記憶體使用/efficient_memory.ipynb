{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¼‰å…¥æ•¸æ“šé›†è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'review'],\n",
       "    num_rows: 7765\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "'''\n",
    "dataset_dict = load_dataset(\"csv\",data_files=\"./ChnSentiCorp_htl_all.csv\") #splitä¸æŒ‡å®šæœƒå‚³å‡ºDatasetDict\n",
    "dataset_dict['train']\n",
    "'''\n",
    "#æ•´åˆä¸Šé¢2è¡Œæˆç‚º1è¡Œçš„èªæ³•\n",
    "dataset = load_dataset(\"csv\",data_files='./ChnSentiCorp_htl_all.csv', split=\"train\")\n",
    "dataset\n",
    "#æ¸…ç†è³‡æ–™\n",
    "dataset = dataset.filter(lambda example: example['review'] is not None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ•¸æ“šé›†åˆ†é¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 6988\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 777\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = dataset.train_test_split(test_size=0.1)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ•¸æ“šé›†åˆ†è©è™•ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026fb9fcb3f8412b98abb489a2ebab63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6988 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7d184b2d8e432487eb7917a1453379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/777 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 6988\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 777\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')\n",
    "\n",
    "def tokenizer_process(example:dict[str,any]) -> dict[str,any]:\n",
    "    tokenized_example:dict = tokenizer(example['review'], max_length=128, truncation=True)\n",
    "    tokenized_example['labels'] = example['label']\n",
    "    return tokenized_example\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenizer_process,batched=True,remove_columns=datasets['train'].column_names)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å–å¾—é è¨“ç·´æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('google-bert/bert-base-chinese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å»ºç«‹è©•ä¼°å‡½æ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "#acc_metric = evaluate.load('accuracy')\n",
    "#f1_metric = evaluate.load('f1')\n",
    "acc_metric = evaluate.load('evaluate-main/metrics/accuracy/accuracy.py')\n",
    "f1_metric = evaluate.load('evaluate-main/metrics/f1/f1.py')\n",
    "\n",
    "def eval_metric(eval_predict):\n",
    "    predictions, labels = eval_predict\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels)\n",
    "    acc.update(f1)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å»ºç«‹TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir='./checkpoints',\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=128,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model='f1',\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='None',\n",
    "    num_train_epochs=3 #é è¨­ç‚º3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TrainingArguments æ˜¯ Hugging Face transformers ä¸­ Trainer é¡åˆ¥çš„è¨­å®šåƒæ•¸ï¼Œä¸»è¦ç”¨æ–¼æ§åˆ¶æ¨¡å‹è¨“ç·´çš„å„ç¨®è¡Œç‚ºã€‚è®“æˆ‘å€‘è©³ç´°è§£æä½ çš„ TrainingArguments è¨­å®šï¼š\n",
    "\n",
    "1. è¼¸å‡ºç›®éŒ„ (output_dir)\n",
    "\n",
    "output_dir='./checkpoints'\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šæŒ‡å®šè¨“ç·´éç¨‹ä¸­ä¿å­˜æ¨¡å‹æª”æ¡ˆçš„ä½ç½®ã€‚\n",
    "\tâ€¢\tåŸå› ï¼šé€™æ¨£å¯ä»¥åœ¨è¨“ç·´éç¨‹ä¸­è‡ªå‹•ä¿å­˜æª¢æŸ¥é»ï¼ˆcheckpointsï¼‰ï¼Œä»¥ä¾¿åœ¨è¨“ç·´ä¸­æ–·æ™‚èƒ½å¤ ç¹¼çºŒè¨“ç·´ï¼Œæˆ–ç”¨ä¾†åšæ¨è«–ï¼ˆinferenceï¼‰ã€‚\n",
    "\tâ€¢\tæ³¨æ„ï¼šæœ€å¥½ç¢ºä¿é€™å€‹ç›®éŒ„å­˜åœ¨ï¼Œä¸¦ä¸”æœ‰è¶³å¤ çš„ç£ç¢Ÿç©ºé–“ä¾†å­˜æ”¾æ¬Šé‡æª”æ¡ˆã€‚\n",
    "\n",
    "2. æ¯å€‹è£ç½®çš„è¨“ç·´æ‰¹æ¬¡å¤§å° (per_device_train_batch_size)\n",
    "\n",
    "per_device_train_batch_size=64\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šè¨­å®šå–®å€‹ GPUï¼ˆæˆ– CPUï¼‰ä¸Šçš„è¨“ç·´æ‰¹æ¬¡å¤§å°ã€‚\n",
    "\tâ€¢\tåŸå› ï¼šè¼ƒå¤§çš„æ‰¹æ¬¡å¤§å°æœ‰åŠ©æ–¼æ›´ç©©å®šçš„æ¢¯åº¦æ›´æ–°ï¼Œä½†æœƒæ¶ˆè€—æ›´å¤šçš„è¨˜æ†¶é«”ï¼ˆVRAMï¼‰ã€‚64 æ˜¯ä¸€å€‹è¼ƒå¤§çš„å€¼ï¼Œé©åˆé«˜æ•ˆèƒ½ GPUã€‚\n",
    "\tâ€¢\tèª¿æ•´å»ºè­°ï¼š\n",
    "\tâ€¢\tè‹¥ GPU è¨˜æ†¶é«”ä¸è¶³ï¼Œæ‡‰é™ä½æ­¤å€¼ï¼Œå¦‚ 32 æˆ– 16ã€‚\n",
    "\tâ€¢\tè‹¥ä½¿ç”¨å¤šå€‹ GPUï¼Œç¸½æ‰¹æ¬¡å¤§å° = per_device_train_batch_size Ã— GPU æ•¸é‡ã€‚\n",
    "\n",
    "3. æ¯å€‹è£ç½®çš„è©•ä¼°æ‰¹æ¬¡å¤§å° (per_device_eval_batch_size)\n",
    "\n",
    "per_device_eval_batch_size=128\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šè¨­å®šå–®å€‹ GPUï¼ˆæˆ– CPUï¼‰ä¸Šçš„è©•ä¼°æ‰¹æ¬¡å¤§å°ã€‚\n",
    "\tâ€¢\tåŸå› ï¼šåœ¨è©•ä¼°æ™‚ä¸éœ€è¦è¨ˆç®—æ¢¯åº¦ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å¤§å°ä¾†åŠ å¿«è©•ä¼°é€Ÿåº¦ã€‚\n",
    "\tâ€¢\tèª¿æ•´å»ºè­°ï¼š\n",
    "\tâ€¢\tå¦‚æœé¡¯ç¤ºè¨˜æ†¶é«”å……è¶³ï¼Œå¯ä»¥é©ç•¶æé«˜é€™å€‹å€¼ä¾†åŠ é€Ÿè©•ä¼°ã€‚\n",
    "\n",
    "4. è¨˜éŒ„ (logging_steps)\n",
    "\n",
    "logging_steps=10\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šè¨­å®šæ¯ 10 å€‹æ­¥é©Ÿè¨˜éŒ„ä¸€æ¬¡è¨“ç·´æŒ‡æ¨™ï¼ˆå¦‚ lossï¼‰ã€‚\n",
    "\tâ€¢\tåŸå› ï¼šè®“ä½¿ç”¨è€…å¯ä»¥ç›£æ§è¨“ç·´é€²åº¦ï¼Œè€Œä¸æœƒå› ç‚ºå¤ªé »ç¹çš„è¨˜éŒ„è€Œå½±éŸ¿æ•ˆèƒ½ã€‚\n",
    "\tâ€¢\tèª¿æ•´å»ºè­°ï¼š\n",
    "\tâ€¢\tè‹¥æƒ³è¦æ›´ç´°ç·»çš„ç›£æ§ï¼Œå¯æ¸›å°‘é€™å€‹å€¼ï¼ˆå¦‚ 5ï¼‰ã€‚\n",
    "\tâ€¢\tè‹¥è¨“ç·´æ­¥é©Ÿéå¤šï¼Œå¯èƒ½éœ€è¦å¢åŠ æ­¤å€¼ä¾†æ¸›å°‘ log é »ç‡ã€‚\n",
    "\n",
    "5. è©•ä¼°ç­–ç•¥ (evaluation_strategy)\n",
    "\n",
    "evaluation_strategy=\"epoch\"\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šè¨­å®šè©•ä¼°ï¼ˆvalidationï¼‰çš„é »ç‡ã€‚\n",
    "\tâ€¢\tå¯é¸å€¼ï¼š\n",
    "\tâ€¢\t\"no\"ï¼šä¸åšè©•ä¼°ã€‚\n",
    "\tâ€¢\t\"steps\"ï¼šæ¯éš” eval_steps è¨­å®šçš„æ­¥é©Ÿé€²è¡Œä¸€æ¬¡è©•ä¼°ã€‚\n",
    "\tâ€¢\t\"epoch\"ï¼šæ¯å€‹ epoch çµæŸæ™‚é€²è¡Œè©•ä¼°ã€‚\n",
    "\tâ€¢\tåŸå› ï¼šé€™è£¡é¸æ“‡ \"epoch\"ï¼Œè¡¨ç¤ºåœ¨æ¯å€‹å®Œæ•´çš„è¨“ç·´é€±æœŸçµæŸå¾Œï¼ŒåŸ·è¡Œä¸€æ¬¡è©•ä¼°ï¼Œä»¥ç¢ºä¿æ¨¡å‹çš„è¨“ç·´æ•ˆæœã€‚\n",
    "\n",
    "6. æ¨¡å‹å„²å­˜ç­–ç•¥ (save_strategy)\n",
    "\n",
    "save_strategy=\"epoch\"\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šè¨­å®šæ¨¡å‹çš„å„²å­˜é »ç‡ã€‚\n",
    "\tâ€¢\tå¯é¸å€¼ï¼š\n",
    "\tâ€¢\t\"no\"ï¼šä¸å„²å­˜æ¨¡å‹ã€‚\n",
    "\tâ€¢\t\"steps\"ï¼šæ¯ save_steps è¨­å®šçš„æ­¥é©Ÿå­˜ä¸€æ¬¡ã€‚\n",
    "\tâ€¢\t\"epoch\"ï¼šæ¯å€‹å®Œæ•´çš„ epoch å¾Œå­˜ä¸€æ¬¡ã€‚\n",
    "\tâ€¢\tåŸå› ï¼šèˆ‡ evaluation_strategy ä¸€è‡´ï¼Œæ¯å€‹ epoch å¾Œå­˜ä¸€æ¬¡æœ€ä½³æª¢æŸ¥é»ï¼Œæ–¹ä¾¿å¾ŒçºŒå¾®èª¿æˆ–æ¢å¾©è¨“ç·´ã€‚\n",
    "\n",
    "7. æœ€å¤§ä¿å­˜çš„æª¢æŸ¥é»æ•¸é‡ (save_total_limit)\n",
    "\n",
    "save_total_limit=3\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šæœ€å¤šä¿ç•™ 3 å€‹æª¢æŸ¥é»ï¼Œè¶…éé€™å€‹æ•¸é‡å¾Œæœƒè‡ªå‹•åˆªé™¤èˆŠçš„æª¢æŸ¥é»ã€‚\n",
    "\tâ€¢\tåŸå› ï¼š\n",
    "\tâ€¢\tè‹¥ä¸é™åˆ¶ï¼Œå¯èƒ½æœƒå ç”¨å¤§é‡ç£ç¢Ÿç©ºé–“ã€‚\n",
    "\tâ€¢\t3 ä»£è¡¨ä¿ç•™æœ€è¿‘ 3 æ¬¡çš„æœ€ä½³æ¨¡å‹ï¼Œè¶³å¤ é€²è¡Œå›æº¯èˆ‡é¸æ“‡ã€‚\n",
    "\n",
    "8. å­¸ç¿’ç‡ (learning_rate)\n",
    "\n",
    "learning_rate=2e-5\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šè¨­å®š AdamW å„ªåŒ–å™¨çš„å­¸ç¿’ç‡ï¼ˆLearning Rate, LRï¼‰ã€‚\n",
    "\tâ€¢\tåŸå› ï¼š\n",
    "\tâ€¢\t2e-5ï¼ˆ0.00002ï¼‰æ˜¯é©åˆ Transformer æ¨¡å‹çš„é è¨­å¾®èª¿å­¸ç¿’ç‡ã€‚\n",
    "\tâ€¢\tè‹¥å­¸ç¿’ç‡éé«˜ï¼Œæ¨¡å‹å¯èƒ½é›£ä»¥æ”¶æ–‚ï¼ˆloss æ³¢å‹•å¤§ï¼‰ã€‚\n",
    "\tâ€¢\tè‹¥å­¸ç¿’ç‡éä½ï¼Œè¨“ç·´é€Ÿåº¦è®Šæ…¢ã€‚\n",
    "\tâ€¢\tèª¿æ•´å»ºè­°ï¼š\n",
    "\tâ€¢\tè‹¥æ¨¡å‹è¨“ç·´ä¸ç©©å®šï¼Œå¯å˜—è©¦é™ä½ï¼Œå¦‚ 1e-5 æˆ– 5e-6ã€‚\n",
    "\tâ€¢\tè‹¥æ¨¡å‹è¨“ç·´éæ…¢ä¸” loss å¹³ç©©ï¼Œå¯æé«˜å­¸ç¿’ç‡ï¼Œå¦‚ 3e-5ã€‚\n",
    "\n",
    "9. æ¬Šé‡è¡°æ¸› (weight_decay)\n",
    "\n",
    "weight_decay=0.01\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šL2 æ­£å‰‡åŒ–ï¼Œç”¨æ–¼é˜²æ­¢éæ“¬åˆï¼Œè®“æ¬Šé‡æ›´æ–°æ™‚é©ç•¶è¡°æ¸›ã€‚\n",
    "\tâ€¢\tåŸå› ï¼š\n",
    "\tâ€¢\t0.01 æ˜¯è¼ƒå¸¸è¦‹çš„ Transformer æ¬Šé‡è¡°æ¸›å€¼ã€‚\n",
    "\tâ€¢\tè‹¥æ¨¡å‹å®¹æ˜“éæ“¬åˆï¼Œå¯ä»¥é©ç•¶æé«˜ï¼Œå¦‚ 0.02ã€‚\n",
    "\tâ€¢\tè‹¥æ¨¡å‹å­¸ç¿’ç·©æ…¢æˆ–æ•ˆæœä¸å¥½ï¼Œå¯ä»¥é™ä½æ­¤å€¼ï¼Œå¦‚ 0.001ã€‚\n",
    "\n",
    "10. æœ€ä½³æ¨¡å‹çš„è©•ä¼°æŒ‡æ¨™ (metric_for_best_model)\n",
    "\n",
    "metric_for_best_model='f1'\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šè¨­å®šç”¨ä¾†é¸æ“‡æœ€ä½³æ¨¡å‹çš„è©•ä¼°æŒ‡æ¨™ã€‚\n",
    "\tâ€¢\tåŸå› ï¼š\n",
    "\tâ€¢\tf1 é©ç”¨æ–¼ä¸å¹³è¡¡æ•¸æ“šé›†ï¼Œå› ç‚ºå®ƒæ˜¯ Precision å’Œ Recall çš„åŠ æ¬Šå¹³å‡ã€‚\n",
    "\tâ€¢\tè‹¥æ˜¯å›æ­¸å•é¡Œï¼Œå¯æ”¹ç‚º mse æˆ– maeã€‚\n",
    "\tâ€¢\tè‹¥æ˜¯åˆ†é¡å•é¡Œï¼Œä¹Ÿå¯ä½¿ç”¨ accuracyã€‚\n",
    "\n",
    "11. è¼‰å…¥æœ€ä½³æ¨¡å‹ (load_best_model_at_end)\n",
    "\n",
    "load_best_model_at_end=True\n",
    "\n",
    "\tâ€¢\tä½œç”¨ï¼šè¨“ç·´çµæŸæ™‚ï¼Œè‡ªå‹•åŠ è¼‰è©•ä¼°æŒ‡æ¨™æœ€é«˜ï¼ˆæœ€ä½³ï¼‰çš„æ¨¡å‹ã€‚\n",
    "\tâ€¢\tåŸå› ï¼š\n",
    "\tâ€¢\tå¯ç¢ºä¿æœ€å¾Œå¾—åˆ°çš„æ˜¯æœ€ä½³æª¢æŸ¥é»ï¼Œè€Œä¸æ˜¯æœ€å¾Œä¸€å€‹æª¢æŸ¥é»ï¼ˆå› ç‚ºæœ€å¾Œä¸€å€‹å¯èƒ½ä¸æ˜¯æœ€å¥½çš„ï¼‰ã€‚\n",
    "\tâ€¢\tå¦‚æœ metric_for_best_model æ˜¯ f1ï¼Œé‚£éº¼é€™å€‹é¸é …æœƒåŠ è¼‰ f1 æœ€é«˜çš„æ¨¡å‹ã€‚\n",
    "\n",
    "ç¸½çµ\n",
    "\n",
    "åƒæ•¸\tä½œç”¨\tè¨­å®šå€¼\tèªªæ˜\n",
    "output_dir\tå„²å­˜æª¢æŸ¥é»çš„ç›®éŒ„\t'./checkpoints'\té¿å…è¨“ç·´ä¸­æ–·å¾Œä¸Ÿå¤±æ¨¡å‹\\\n",
    "\n",
    "per_device_train_batch_size\tè¨“ç·´æ‰¹æ¬¡å¤§å°\t64\tå–æ±ºæ–¼ GPU è¨˜æ†¶é«”å¤§å°\n",
    "\n",
    "per_device_eval_batch_size\tè©•ä¼°æ‰¹æ¬¡å¤§å°\t128\tè©•ä¼°æ™‚å¯è¨­è¼ƒå¤§å€¼\n",
    "\n",
    "logging_steps\tè¨“ç·´æ—¥èªŒé »ç‡\t10\tæ§åˆ¶ log çš„é »ç‡\n",
    "\n",
    "evaluation_strategy\tè¨“ç·´æœŸé–“ä½•æ™‚è©•ä¼°\t\"epoch\"\tæ¯å€‹ epoch çµæŸå¾Œè©•ä¼°\n",
    "\n",
    "save_strategy\tè¨“ç·´æœŸé–“ä½•æ™‚å­˜æ¨¡å‹\t\"epoch\"\tæ¯å€‹ epoch å¾Œå­˜\n",
    "\n",
    "save_total_limit\tä¿ç•™å¤šå°‘å€‹æª¢æŸ¥é»\t3\té¿å…ç£ç¢Ÿç©ºé–“ä¸è¶³\n",
    "\n",
    "learning_rate\tå­¸ç¿’ç‡\t2e-5\tTransformer å¾®èª¿çš„å¸¸è¦‹å€¼\n",
    "\n",
    "weight_decay\tæ¬Šé‡è¡°æ¸›\t0.01\té˜²æ­¢éæ“¬åˆ\n",
    "\n",
    "metric_for_best_model\tæœ€ä½³æ¨¡å‹çš„æŒ‡æ¨™\t'f1'\té©ç”¨æ–¼åˆ†é¡ä»»å‹™\n",
    "\n",
    "load_best_model_at_end\tè¨“ç·´çµæŸå¾Œæ˜¯å¦è¼‰å…¥æœ€ä½³æ¨¡å‹\tTrue\tå–æœ€å¥½çš„æ¨¡å‹\n",
    "\n",
    "é€™äº›åƒæ•¸è¨­å®šé©åˆ Transformer å¾®èª¿ï¼Œä½†å¯ä»¥æ ¹æ“šç¡¬é«”è³‡æºèˆ‡æ•¸æ“šé›†ç‰¹æ€§é€²è¡Œèª¿æ•´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=eval_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç™»å…¥hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89bcb71d8e14183912817b9f99f6c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šå‚³modelå’Œtokenizerè‡³huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53181f3b7a444405b6aaf5bc6c997015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb21008ea6a4a6f97178b24e057f5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/409M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c67c5c1e5e8490691f170e139488fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.push_to_hub(\"roberthsu2003\") #ç”±æ–¼æœ‰è¨­./checkpoints,æ‰€ä»¥è‡ªå‹•ç”¢ç”Ÿcheckpointsçš„repo,ä¹Ÿæœƒè‡ªå‹•ä¸Šå‚³è©•ä¼°è‡³repo\n",
    "#åŒæ™‚è¦ä¸Šå‚³tokenizer\n",
    "model_name = \"roberthsu2003/checkpoints\"\n",
    "tokenizer.push_to_hub(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹è¼‰å’Œä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50ddf7d17ed4344ad57ae88ca167abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/895 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2427202e3c4444ed8971420a447c217c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/409M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ac0c7e976c46d1816887e541b82f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60feed3f2b04670b5215f18a44de493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32750acb0ea4b88b7978d0facce611f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/439k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68e2798731e4c37a1fb84fc456d794e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æœå‹™äººå“¡éƒ½å¾ˆè¦ªåˆ‡ æ­£è©•\n",
      "æœå‹™äººå“¡éƒ½ä¸è¦ªåˆ‡ è² è©•\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "id2_label = {'LABEL_0':\"è² è©•\",'LABEL_1':\"æ­£è©•\"}\n",
    "pipe = pipeline('text-classification', model=\"roberthsu2003/checkpoints\")\n",
    "\n",
    "sen=\"æœå‹™äººå“¡éƒ½å¾ˆè¦ªåˆ‡\"\n",
    "print(sen,id2_label[pipe(sen)[0]['label']])\n",
    "\n",
    "sen1=\"æœå‹™äººå“¡éƒ½ä¸è¦ªåˆ‡\"\n",
    "print(sen1,id2_label[pipe(sen1)[0]['label']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
