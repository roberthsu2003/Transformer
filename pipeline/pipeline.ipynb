{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果有Iprogress not found的錯誤,更新ipywidgets\n",
    "\n",
    "`conda install -c conda-forge ipywidgets`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看pipeline支援的任務類型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-classification  ->  audio\n",
      "automatic-speech-recognition  ->  multimodal\n",
      "text-to-audio  ->  text\n",
      "feature-extraction  ->  multimodal\n",
      "text-classification  ->  text\n",
      "token-classification  ->  text\n",
      "question-answering  ->  text\n",
      "table-question-answering  ->  text\n",
      "visual-question-answering  ->  multimodal\n",
      "document-question-answering  ->  multimodal\n",
      "fill-mask  ->  text\n",
      "summarization  ->  text\n",
      "translation  ->  text\n",
      "text2text-generation  ->  text\n",
      "text-generation  ->  text\n",
      "zero-shot-classification  ->  text\n",
      "zero-shot-image-classification  ->  multimodal\n",
      "zero-shot-audio-classification  ->  multimodal\n",
      "image-classification  ->  image\n",
      "image-feature-extraction  ->  image\n",
      "image-segmentation  ->  multimodal\n",
      "image-to-text  ->  multimodal\n",
      "object-detection  ->  multimodal\n",
      "zero-shot-object-detection  ->  multimodal\n",
      "depth-estimation  ->  image\n",
      "video-classification  ->  video\n",
      "mask-generation  ->  multimodal\n",
      "image-to-image  ->  image\n"
     ]
    }
   ],
   "source": [
    "from transformers.pipelines import SUPPORTED_TASKS\n",
    "\n",
    "for k, v in SUPPORTED_TASKS.items():\n",
    "    print(k,' -> ' ,v['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如何查看支援類型的細節說明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "支援任務:audio-classification\n",
      "{'default': {'model': {'pt': ('superb/wav2vec2-base-superb-ks', '372e048')}},\n",
      " 'impl': <class 'transformers.pipelines.audio_classification.AudioClassificationPipeline'>,\n",
      " 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForAudioClassification'>,),\n",
      " 'tf': (),\n",
      " 'type': 'audio'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "for k, value in SUPPORTED_TASKS.items():\n",
    "    print(f'支援任務:{k}')\n",
    "    pprint(value)\n",
    "    break\n",
    "\n",
    "#default->是使用的預設模型\n",
    "#impl->對應的class\n",
    "#pt->支援pytorch模型\n",
    "#tf->支援TensorFlow模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingFace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
